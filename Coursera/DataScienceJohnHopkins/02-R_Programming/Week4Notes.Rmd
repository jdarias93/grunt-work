---
title: "Week 4 Notes"
output: html_notebook
---

# str() Function
* Compactly display the internal structure of an R object.
- A diagnostic function and an alternative to "summary"
- It is especially well-suited to compactly display the (abbreviated) contents of 
  (possibly nested) lists.
- Roughly one line per basic object.

```{r}
str(str) # str() gives you the arguments that a function takes.
str(lm)
x <- rnorm(100,2,4)
summary(x) # summary() gives statistics BUT...
str(x) # str() gives you more info, like whether or not this is a numeric vector

f <- gl(40,10) # A factor with forty levels
summary(f) # Gives you a table of how many of each level there is in f
str(f) # Gives you the object class and how many levels

library(datasets)
head(airquality) 
str(airquality) # Gives each column and what kind of classes it contains.
m <- matrix(rnorm(100),10,10)
str(m) # Gives us dimensions of matrix
m[,1]

s <- split(airquality, airquality$Month) # Using split to create list separated by levels
str(s) # Using str() on s gives a highly detailed break-down of the list created in split()
```

# Simulation: Generating Random Numbers
* Functions for probability distributions in R
- rnorm: Generate random Normal variates with a given mean and SD
- dnorm: Evaluate Normal probability density (with a given mean/SD) at point (or vector of
  points)
- pnorm: Evaluate the cumulative distribution function for a Normal distribution
- rpois: Generate random Poisson variates with a given rate

* Probability distribution functions usually have four functions associated with them.
* They are prefixed with a
        - d for density
        - r for random number generation
        - p for cumulative distribution
        - q for quantile function
```{r}
str(dnorm) # See what arguments these take
str(pnorm)
str(qnorm)
str(rnorm)
```

* Anytime you generate random numbers, you must set a seed, which will ensure your work
  is reproducible.
```{r}
set.seed(1)
rnorm(5)
# The seed is now unset and must be reset again.
set.seed(1)
rnorm(5) # And you get the same numbers.
```

* Generating poisson data
```{r}
str(rpois)
rpois(10,1)
ppois(2,2) # Cumulative distribution, output is Pr(x <= 2)

```

# Simulation: Generating Random Numbers From a Linear Model
* Suppose we want to simulate from the following linear model:
- y=B0 + B1x + e where e ~ N(0,2), B0 = 0.5, and B1 = 2
```{r}
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e # Our equation above
summary(y)
plot(x,y) # A linear relationship
```
* What if x is binary?
```{r}
set.seed(10)
x <- rbinom(100,1,0.5) # Here is the binomial data
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
summary(y)
plot(x,y)
```

# Simulation: Generating Random Numbers for a Generalized Linear Model
* Suppose we want to simulate from a Poisson model where
- Y ~ Poisson(mu)
- log mu = B0 + B1x
        - B0 = 0.5
        - B1 = 0.3
```{r}
# We need rpois function
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu)) # Notice how we have to cancel out the log with exp()
summary(y)
plot(x,y)
```

# Simulation: Random Sampling
* The sample() function draws randomly from a specified set of scalar objects allowing 
  you to sample from arbitrary distributions
```{r}
set.seed(1)
sample(1:10,4) # Randomly sample 4 numbers from a vector of numbers 1-10
sample(1:10,4) # This changes everytime you iterate GIVEN YOUR SEED
sample(letters,5)
sample(1:10)
sample(1:10)
sample(1:10, replace=TRUE) # Sampling with replacement.
```

# Simulation: Summary
* Drawing samples from specific probability distributions can be done with r functions
* Standard distributions are built in: Normal, Poisson, Binomial, Exponential, Gamma...
* Sample function can be used to draw random samples from arbitrary vectors
* Setting the random number generator seed via set.seed is critical for reproducibility

# R Profiler
* Useful when you are developing larger programs or big data analyses
* Really handy tool to figure out exactly why its taking so much time and how to fix it.

## Why is My Code So Slow?
* Profiling is a systematic way to examine how much time is spent in different parts of
  of a program
* Useful when trying to optimize your code
* Often code runs fine once, but what if you have to put it in a loop for 1000 
  iterations? Is it still fast enough?
* Profiling is better than GUESSING.

## On Optimizing Your Code
* Getting the biggest impact on speeding up code depends on knowing where the code 
  spends most of its time
* This cannot be done without performance analysis or profiling
* In general, DON'T THINK ABOUT PERFORMANCE AT FIRST.

## General Principles of Optimization
* Design first, then optimize (Lest you introduce bugs)
* Remember: Premature optimization is the root of all evil.
* Measure (collect data), don't guess
* If you're going to be a scientist, you need to apply the same principles here!
* The way to collect the data for optimization is PROFILING

## Using system.time()
* Takes an arbitrary R expression as input (can be wrapped in curly braces) and returns
  the amount of time taken to evaluate the expression
* Computes the time (in seconds) needed to execute an expression
- If there's an error, gives time until the error occurred
* Returns an object of class proc_time
- User Time: Time charged to the CPUs for this expression
- Elapsed time: "Wall clock" time
* Usually, user and elapsed time are relatively close for straight computing tasks
* Elapsed time may be greater than user time if the CPU spends a lot of time waiting
  around
* Elapsed time may be smaller than the user time if your machine has multiple cores/
  processors (and is capable of using them)
- Multi-threaded BLAS libraries (vecLib/Accerlerate, ATLAS, ACML, MKL)
- Parallel processing via the parallel package

```{r}
## An example where Elapsed Time > User Time
system.time(readLines("http://www.jhsph.edu")) # Reading a website
# You have to wait for the connection and reading to occur, therefore elapsed time
# will be greater than user time.

## ... Elapsed time < User Time
hilbert <- function(n) {
        i <- 1:n
        1/outer(i-1,i,"+")
}
x <- hilbert(1000)
system.time(svd(x)) # svd(x) uses Accerlerate framework on a mac.
# User time is larger because the library SPLIT the computations across two cores.
# Essentially elapsed * # cores you're using.
```

## Timing Longer Expressions
```{r}
# Wrap everything in a curly brace.
system.time({
        n <- 1000
        r <- numeric(n)
        for (i in 1:n) {
                x <- rnorm(n)
                r[i] <- mean(x)
        }
})
```

## Beyond system.time()
* Using system.time() allows you to test certain functions or code blocks to see if they
  are taking excessive amounts of time
* Assumes you already know where the problem is and can call system.time() on it
* But what if you don't know where to start?

# The R Profiler
* The Rprof() function starts the profiler in R
- R must be compiled with profiler support (but this is usually the case)
* The summaryRprof() function summarizes the output from Rprof() otherwise it is not 
  readable
* DO NOT use system.time() and Rprof() together or you will be sad.
* Rprof() keeps track of the function call stack at regularly sampled intervals and 
  tabulates how much time is spent in each function
* Default sampling interval is 0.02 seconds
* NOTE: If your code runs very quickly, the profiler is not useful, but then you prolly
  don't need it in that case

## Using summaryRprof()
* The summaryRprof() function tabulates the R profiler output and calculates how much 
  time is spent in which function
* Two methods for normalizing data
* "by.total" divides the time spent in each function by total run time
* "by.self" does the same but first subtracts out time spent in functions above the call
  stack

## Summary
* Rprof() runs the profiler for performance of analysis of R code
* summaryRprof() summarizes the output of Rprof() and gives percent of time spent in 
  each function (with two types of normalization)
* Good to break your code into functions so that the profiler can give useful info about
  where time is being spent
* C or Fortran code is not profiled

  
 



