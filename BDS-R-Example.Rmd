---
title: "R Notebook"
output: html_notebook
---

# Loading Data into R
```{r}
# Get your working directory in order with getwd() and setwd("")
setwd("/Users/jdarias/Desktop/bds-files/chapter-08-r/")
d <- read.csv("Dataset_S1.txt") # Load data
```

# Exploring and Transforming Dataframes
```{r}
head(d, n=3) 
# Check data

nrow(d) 
# Check # rows

ncol(d) 
# Check # columns

dim(d) 
# Check dimensions (r c)

colnames(d) 
# Check column names for discrepancies; "X.GC" instead of "%GC"

colnames(d)[12] <- "Percent.GC" 
# Changed X.GC

d$depth 
# Access a single column of a dataframe with $

mean(d$depth) 
# The mean of one column in d

summary(d$depth) 
# Summary stats of one column in d

d[ , 1:2] 
# Subsetting columns

d[, c("start","end")] 
# We can also use column names to acheive the same end

d[1,c("start","end")] 
# Only first row of start and end columns

d[, "start", drop=FALSE]
# Disables subsetting as vector (retains dataframe format)

d$cent <- d$start >= 25800000 & d$end <= 29700000 
```

## Creating Dataframes From Scratch
```{r}
x <- sample(1:50,300,replace=TRUE) 
# Samples numbers 1-50, 300 times

y <- 3.2*x + rnorm(300,0,40) 
# Function

d_sim <- data.frame(y=y, x=x) 
# Represents vectors as a dataframe
```


## Logical vector for determining if window within a centromeric region
```{r}
table(d$cent) 
# See how many rows were within the centromeric region

sum(d$cent) 
# Another way to see how many rows were within region

d$diversity <- d$Pi / (10*1000) 
# Rescaling data
```

# Exploring Data Through Slicing and Dicing
```{r}

summary(d$total.SNPs)
# SNPs are heavily skewed right: Q3 = 12 but Max = 93! Let's investigate

d$total.SNPs >= 85 
# Create logical vector

d[d$total.SNPs >= 85, ] 
# Subset according to logical vector
# Only rows that have a TRUE value (total.SNPs >= 85) will be kept.

d[d$Pi > 16 & d$Percent.GC > 80, ] 
# A more elaborate subsetting

d[d$Pi > 16 & d$Percent.GC > 80, c("start","end","depth","Pi")]
# One more time but asking for specific columns

d$Percent.GC[d$Pi > 16] 
# Asking for a specific column using a logical vector fromn ANOTHER COLUMN!!!

summary(d$depth[d$Percent.GC >= 80])
# Subsetting to summarize average depth in the >= 80 window; it is low compared to:
summary(d$depth[d$Percent.GC < 80])

summary(d$Pi[d$cent])
# Looking at Pi by windows falling in our above centromere window...

summary(d$Pi[!d$scent])
# ...and those that fall outside it.

d$Pi > 3
# which() takes a logical vector and returns the positions of all TRUE values!

which(d$Pi>3)
which(d$Pi>10)[1:4] 
# First four TRUE values

d[which.min(d$total.Bases),] 
# Returns row which has the minimum element

d[which.max(d$depth),] 
# Returns row with the maximum element

# So the centromere appears to have higher nucleotide diversity than other regions
# Sometimes subsetting expressions in brackets is redundant so we can use subset()

# subset() takes two arguments: dataframe and conditions to include a row:
subset(d,Pi > 16 & Percent.GC > 80)
# A third argument supplied to specify which columns to include:
subset(d, Pi > 16 & Percent.GC > 80,
       c(start,end,Pi,Percent.GC,depth))
# subset is special in that we don't have to "quote" column names
```

# Exploring Data Visually with ggplot2 I: Scatterplots and Densities
* Every R user should be acquainted with base graphics but we're gonna focus on ggplot2
```{r}
install.packages("ggplot2")
library(ggplot2)

# Let's create a scatterplot of nucleotide diversity along chromosome
# We want to add a column called position to our dataframe that is the midpoint between 
# each window:
d$position <- d$end + d$start / 2
ggplot(d) + geom_point(aes(x=position, y=Pi)) 
# ggplot only works with dataframes
# geom_point is a layer we add in order to create a scatterplot
# "geoms" are geometric objects with many aesthetic attributes
# We specify aesthetic attribute mapping to columns using function aes:
ggplot(d,aes(x=position, y=Pi)) + geom_point()
# Lets exclude missing diversity estimates from the centromere:
ggplot(d) + geom_point(aes(x=position, y=Pi, color=cent))
# The above figure shows missing diversity estimates around the centromere
# This is intentional, as centromeric and heterochromatic regions were excluded in this # study.

# Overplotting can be an issue, making it so that we can't get a good sense of
# diversity distribution from the figure. One way to alleviate this is by making some
# points transparent so only regions with multiple overlapping points appear dark
ggplot(d) + geom_point(aes(x=position,y=Pi), alpha=0.01)
# Notice that we put alpha OUTSIDE of aes(); this makes the argument apply to ALL data 
# points.

# Now we look at diversity density across ALL positions. We used geom_density() for 
# this.
ggplot(d) + geom_density(aes(x=Pi), fill="black")
# We can also create separate density plots, grouping data by column mapped to the color
# aesthetic and using colors to indicate the different densities
ggplot(d) + geom_density(aes(x=Pi, fill=cent),alpha=0.4)
# In the above line, we fill the densities according to whether the plotted values are
# within the centromere or not (cent)

# We now see that diversity is skewed to more extreme values in centromeric regions!
# Mapping columns to additional aesthetic attributes can reveal patterns and info in
# the data that may NOT be apparent in simple plots!
```
* Axis Labels, Plot Titles, and Scales
- You can change axes and plot labels with xlab(), ylab(), and ggtitle(), respectively.
- You can set limits for continuous axes using scale_x_continuous(limits=c(start,end))
- You can changes axes to log 10 scales with scale_x/ylog10()

# Exploring Data Visually with ggplot2 II: Smoothing
* Adding smoothing lines to plots using geom_smooth() allows us to fit a smoothing curve
  to data in order to tease out unexpected trends in the data
* In the next example, we want to superimpose a smooth curve on a scatterplot portraying
  the relationship between sequencing depth and total number of SNPs
```{r}
ggplot(d, aes(x=depth, y=total.SNPs)) + geom_point() + geom_smooth()
# Visualizing data in this way reveals a well-known relationship between depth and SNPs
# Higher sequencing depths increases power to detect and call SNPs
# However, higher and lower GC content regions DECREASE read coverage (depth), which
# we can illustrate in a plot:
ggplot(d, aes(x=Percent.GC, y=depth)) + geom_point() + geom_smooth()
```

# Binning Data with cut() and Bar Plots with ggplot2
* We can extract info from complex datasets by reducing data resolution through BINNING.
- In other words, we place continuous numeric values within a discrete number of ranged   bins.
* We bin data through cut() in R, like so:
```{r}
d$GC.binned <- cut(d$Percent.GC,5) # Cuts data into 5 equally-sized bins (levels)
d$GC.binned
table(d$GC.binned) # The distribution of the binned data.

# We can bin with percentage breaks
cut(d$Percent.GC, c(0,25,50,75,100))
sum(is.na(cut(d$Percent.GC, c(0,25,50,75,100)))) # Checking if this generates NAs
ggplot(d) + geom_bar(aes(x=GC.binned)) # Binned data histogram
ggplot(d) + geom_bar(aes(x=Percent.GC)) # Continuous data histogram

# Depth and GC content story comes out again here, where low and high GC content windows
# have lower depth.
ggplot(d) + geom_density(aes(x=depth, linetype=GC.binned),alpha=0.5)
# When we DON'T group by G.binned, the story disappears
ggplot(d) + geom_density(aes(x=depth),alpha=0.5)
# Trying other columns
ggplot(d) + geom_density(aes(x=Pi, linetype=GC.binned),alpha=0.5)
ggplot(d) + geom_density(aes(x=total.SNPs, linetype=GC.binned),alpha=0.5)


# Bin widths can drastically alter how we view/understand data!!!
```
* Finding the Right Bin Width
```{r}
# Try different binwidths using the binwidth=X argument
ggplot(d) + geom_histogram(aes(x=Pi), binwidth=1) + 
        scale_x_continuous(limits=c(0.01, 80)) 
ggplot(d) + geom_histogram(aes(x=Pi), binwidth=0.05) + # Undersmoothing
        scale_x_continuous(limits=c(0.01, 80))
ggplot(d) + geom_histogram(aes(x=Pi), binwidth=2) +    # Oversmoothing
        scale_x_continuous(limits=c(0.01, 80))
```

# Merging and Combining Data: Matching Vectors and Merging Dataframes
* Bioinformatics analyses involve connecting many numerous datasets: sequencing data,
  genomic features, etc.
* The ability to connect different datasets to tell a cohesive story will become an 
  increasingly more important analysis skill
```{r}
# Simple Operation to check if some a vector's values are in another vector: %in%
c(4,3,-1) %in% c(1,3,4,8) # Outputs a logical vector with equal length as left vector
setwd("/Users/jdarias/Desktop/grunt-work/bds-files/chapter-08-r/")
reps <- read.delim("chrX_rmsk.txt.gz",header=TRUE)
head(reps,3)
class(reps$repClass) # This is a factor column
levels(reps$repClass)

# It would be tedious to construct a statement to select these values using logical 
# operators; instead we create a vector and use %in%

common_repclass <- c("SINE","LINE","LTR","DNA","Simple_repeat")
reps[reps$repClass %in% common_repclass, ]
# This gives us all rows that have the 5 rep classes we want.

# Creating logical vectors programmatically by calculating the five most common repeat 
# classes:
sort(table(reps$repClass), decreasing=TRUE)[1:5] # Gives top five common rep classes
top5_repclass <- names(sort(table(reps$repClass), decreasing=TRUE)[1:5]) # Vectorizes
```

* %in% is just a simplified version of another function called match()
- x %in% y returns TRUE/FALSE for each value in x depending on whether it is in y
- match(x,y) returns first occurence of each of x's values in y.
```{r}
# A match() example:
match(c("A","C","E","A"),c("A","B","A","E"))
# x[1] is found in the y[1], so 1 is printed. x[2] is not found in y, so NA is produced.
# And so on.

```
* match()'s output can be used to join 2 dataframes together by a shared column
- We can use this to replicate an important finding in human recombination bio
* First dataset contains estimates of the recomb rate for all windows within 40 kb of 
  each motif. The second contains which repeat each motif occurs in.
- Goal is to merge these datasets to look at the local effect of recombination of each 
  motif on specific repeat backgrounds.
```{r}
setwd("/Users/jdarias/Desktop/bds-files/chapter-08-r/")
mtfs <- read.delim("motif_recombrates.txt",header=TRUE)
rpts <- read.delim("motif_repeats.txt", header=TRUE)
head(mtfs, 3)
head(rpts,3)
```
* To combine datasets, you must always consider the structure of both datasets
- In mtfs, each motif is represented across multiples ROWS; each row gives the distance 
  between a focal motif and a window over which recomb rate was estimated
- Our goal is to merge the column "name" in the rpts datafarme into the mtfs column,
  so we know which repeat each motif is contained in (if any)
- The link between these datasets are the positions of each motif, identified by the
  chromosome and motif start position columns chr and motif_start. 
```{r}
# Here we concatenate these columns into a single key string column to simplify merging
mtfs$pos <- paste(mtfs$chr, mtfs$motif_start, sep="-")
rpts$pos <- paste(rpts$chr, rpts$motif_start, sep="-")
# This pos common is now the COMMON KEY between two datasets

# Now we want to know how many mtfs motifs have a corresponding entry in rpts 
table(mtfs$pos %in% rpts$pos) # 9218 TRUE.

# Let's pull them out using match(), which tells us where each of the mtfs$pos keys
# occur in rpts$pos
i <- match(mtfs$pos, rpts$pos) # Creates indexing vector
table(is.na(i)) # Number of NAs match the number of mts$pos elements NOT in rprts$pos

# Now let's use that indexing vector to merge.
mtfs$repeat_name <- rpts$name[i]

# You can do all the above in one line also:
mtfs$repeat_name <- rpts$name[match(mtfs$pos, rpts$pos)]

# The last step: Validation.
head(mtfs[!is.na(mtfs$repeat_name), ], 3)

# So we've combined rpts$name directly into our mtfs dataframe (left outer join)
# Not all motifs have entires in rpts so some values in mtfs$repeat_name are NA
# We can remove them like so:
mtfs_inner <- mtfs[!is.na(mtfs$repeat_name), ]
nrow(mtfs_inner) # Again confirming that there are 9218 motif matches
```
* match() is a general way to merge data in R, revealing the gritty details involved in
  merging data necessary to avoid pitfalls, but there is another function: merge()
```{r}
# merge() can directly merge two datasets:
recm <- merge(mtfs,rpts, by.x = "pos", by.y="pos") # An INNER join
head(recm, 2)
recm_left <- merge(mtfs,rpts,by.x="pos",by.y="pos",all.x=TRUE) # A left OUTER join
head(recm_left, 3)
```

# Using ggplot2 Facets
* Once merged, we can now explore the data with visualization using FACETS
* Facets allow us to visualize grouped data with a series of separate adjacent plots
  for each group
```{r}
p <- ggplot(mtfs, aes(x=dist, y=recom)) + geom_point(size=1) # Step 1
p <- p + geom_smooth(method="loess",se=FALSE,span=1/10) # Step 2
print(p) # Bringing it together
```

* There is a large amount of heterogeneity we're not accounting for, which could be
  washing out signal; here we employ faceting to pick apart the data.
```{r}
# Lets see if any motifs have noticeably different effects on local recombination
unique(mtfs$motif)
# Let's group and color the loess curves by motif sequence
ggplot(mtfs,aes(x=dist,y=recom)) +
        geom_point(size=1) +
        geom_smooth(aes(color=motif), method="loess",se=FALSE,span=1/10)

# Alternatively, split motifs apart using facet_wrap()
ggplot(mtfs,aes(x=dist,y=recom)) +
        geom_point(size=1, color="grey") +
        geom_smooth(method="loess",se=FALSE, span=1/10) +
        facet_wrap(~ motif) # This creates a panel for each level and wraps around horiz

```

# More R Data Structures: Lists
* Dataframes are lists. Lists can contain any combinations of classes
```{r}
# List Example
adh <- list(chr="2L", start=1461555L, end=14618902L, name="Adh")
adh[1:2] # Gives first two elements of list
adh[[2]] # Returns only the second element, not as a list.
is.list(adh[[2]]) # False.

# We can create new elements in a list using the list position syntax $
adh$id <- "FBgn0000055" # New ID element created
adh$chr <- "chr2L" # Changing old element
adh$id <- NULL # Removes ID element.
```

# Writing and Applying Functions to Lists with lapply() and sapply()
* Mastering these is tricky, but will serve you well in R.

## Using laaply()
```{r}
# Generate list of numeric values:
ll <- list(a=rnorm(6, mean=1),b=rnorm(6,mean=4),c=rnorm(6,mean=6))
ll

## Create an empty numeric vector for the means
ll_means <- numeric(length(ll))
ll_means

# Loop over each list element and calculate mean
for (i in seq_along(ll)) {
        ll_means[i] <- mean(ll[[i]])
}
ll_means

# This is not idiomatic R; the better approach is to use lapply:
lapply(ll, mean) # One line! Generates a list of 3 numeric values

# The parallelization of lapply() is possible with mclapply()
# If one of your elements in ll had an NA, then mean would return NA unless we
# ignore them by calling mean() with na.rm=TRUE

ll$a[3] <- NA # Replaces index 3 with NA
lapply(ll,mean) # :(
lapply(ll,mean,na.rm=TRUE) # And we ignore the NA
```

## Writing Functions
* We can also write a wrap function to run before lapply to remove NAs automatically
```{r}
meanRemoveNA <- function(x) mean(x,na.rm=TRUE)
lapply(ll, meanRemoveNA)

# Alternative, we don't even need to make a new function to do the same thing:
lapply(ll, function(x) mean(x, na.rm=TRUE))

# Let's create a more polished function that will warn the user when it encounters
# and automatically removes missing values
meanRemoveNAVerbose <- function(x, warn=TRUE) {
        if (any(is.na(x)) && warn) {
                warning("removing some missing values!")
        }
mean(x,na.rm=TRUE)
}
meanRemoveNAVerbose(ll)
```

## Digression: Debugging R Code
* Your code will have bugs. Here are some tools to kill them.
* browser(): Pauses execution at a specified point in your code and runs it line-by-line
```{r}
foo <- function(x) {
        a <- 2
        browser()
        y <- x + a
        return(y)
}
foo(1)

# From the browser() work space, you can execute the next line (n), continue running 
# (c), or quit (Q). We can check variable values with ls() or by calling them directly.

```







